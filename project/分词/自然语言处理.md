## 自然语言处理

nlp

natural language process

### 分词

jieba



我是小明



我 | 是 | 小明

### 提取词干

去除停用词

停用词： 是，哈，

### 语法树





JIEBA WORDCLOUD

先通过分词，写成一个词的统计，wordcount统计词频，根据词频生成词云图



IF 文档词频

一篇文章中某个词出现的频率占总词频的比例

IF越大，说明这个词越重要



如，在某篇政府报告中，多次出现，改善民生，控制经济走向等关键词，说明，这篇报告是关于这方面的，那么我就可以给他打个标签“民生”， “经济”，标签多了，就可以根据这个标签去索引相关文章



IDF，是逆文档词频，指一个词在多篇文章中出现的频率，

对于多篇文章讲，出现的文章越多，重要性越低

如我这个词，在统计的十多篇文档中都是较为高频的词汇，那么我们就认为他不是关键词，有可能是虚词或是停用词



我是小明，我爱中国，我很好。



使用jieba分词



